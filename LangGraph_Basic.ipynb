{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrMkwNDarCKk",
        "outputId": "6f490121-77ed-4498-fd92-c291ff306434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -qU langgraph==0.2.45 langchain-google-genai==2.0.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "api_key = \"AIzaSyD4370HUDdgiyXE5kxvxrm3tb1hn4LC7Q4\"\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "\n",
        "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "xJefDfzdrSjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import add_messages\n",
        "\n",
        "class OrderState(TypedDict):\n",
        "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
        "\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    order: list[str]\n",
        "    finished:bool\n",
        "\n",
        "ORDERBOT_SYSINT = {\n",
        "    \"system\",\n",
        "    \"You are an OrderBot, an interactive cafe ordering system. A human will talk to you about the \"\n",
        "    \"available products you have and you will answer any questions about menu items (and only about \"\n",
        "    \"menu items—no off-topic discussion, but you can chat about the products and their history). \"\n",
        "    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n",
        "    \"and send to the ordering system after confirming the order with the human.\"\n",
        "    \"\\n\"\n",
        "}\n",
        "\n",
        "WELCOME_MSG = \"Welcome to the PESU cafe. Type 'q' to quit. How may I serve you today?\"\n"
      ],
      "metadata": {
        "id": "Uy7CqeApr0yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai==2.0.4"
      ],
      "metadata": {
        "id": "1Y94ZeMXvuyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI # Corrected import statement\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "\n",
        "def chatbot(state: OrderState) -> OrderState:\n",
        "\n",
        "  \"\"\"The chat bot itself \"\"\"\n",
        "  message_history = [ORDERBOT_SYSINT] + state[\"messages\"]\n",
        "  return {messages: llm.generate(message_history)}\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Corrected method name from 'edd_edge' to 'add_edge'\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "jFEkqUzgt6Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display # Corrected import statement\n",
        "\n",
        "Image(chat_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "TU1lb_EzvNY5",
        "outputId": "8dc059c1-e5ed-469a-ba1d-7a4ef7ad5c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI # Corrected import statement\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "\n",
        "def chatbot(state: OrderState) -> OrderState:\n",
        "\n",
        "  \"\"\"The chat bot itself \"\"\"\n",
        "  message_history = [ORDERBOT_SYSINT] + state[\"messages\"]\n",
        "  # Use \"messages\" as the key in the dictionary to match the state structure\n",
        "  return {\"messages\": llm.generate(message_history)}\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Corrected method name from 'edd_edge' to 'add_edge'\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "jlD0ga50wFLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI # Corrected import statement\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain.schema import SystemMessage # Import SystemMessage\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
        "\n",
        "def chatbot(state: OrderState) -> OrderState:\n",
        "\n",
        "  \"\"\"The chat bot itself \"\"\"\n",
        "  # Convert ORDERBOT_SYSINT to a SystemMessage object\n",
        "  system_message = SystemMessage(content=ORDERBOT_SYSINT.pop())\n",
        "  message_history = [system_message] + state[\"messages\"]\n",
        "  # Use \"messages\" as the key in the dictionary to match the state structure\n",
        "  return {\"messages\": llm.generate(message_history)}\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Corrected method name from 'edd_edge' to 'add_edge'\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "G0dAIlfAwMSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "def human_node(state: OrderState) -> OrderState:\n",
        "  \"\"\"Display the last model messsage to the user and recieve the user's input\"\"\"\n",
        "  last_msg = state[\"messages\"][-1]\n",
        "  print(\"Model:\",last_msg.content)\n",
        "\n",
        "  user_input = input(\"User:\")\n",
        "\n",
        "  if user_input in {\"q\", 'quit', 'exit', \"Goodbye\"}:\n",
        "    state[\"finished\"] = True\n",
        "\n",
        "  return state | {'messages':[(\"user\", user_input)]}\n",
        "\n",
        "def chatbot_with_welcome_msg(state: OrderState) -> OrderState:\n",
        "  \"\"\"the chatbpt itself\"\"\"\n",
        "\n",
        "  if state[\"messages\"]:\n",
        "    new_output = llm.invoke([ORDERBOT_SYSINT] + state[\"messages\"])\n",
        "  else:\n",
        "    new_output = AIMessage(content = WELCOME_MSG)\n",
        "\n",
        "  return state | {\"messages\": [new_output]}\n",
        "\n",
        "#start building a new graph\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", \"human\");\n"
      ],
      "metadata": {
        "id": "enS0QsjQwUGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Literal # Import Literal from typing\n",
        "\n",
        "def maybe_exit_human_node(state: OrderState) -> Union[str, Literal[\"__end__\"]]: #Changed to Union and literal string\n",
        "  \"\"\"route to the chatbot, unless it looks like the user is exiting\"\"\"\n",
        "  if state.get(\"finished\",False):\n",
        "    return END # Assuming END has the value \"__end__\"\n",
        "  else:\n",
        "    return \"chatbot\"\n",
        "\n",
        "graph_builder.add_conditional_edges(\"human\",maybe_exit_human_node)\n",
        "\n",
        "chat_with_human_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "XeLpCbE-wsLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = chat_with_human_graph.invoke({\"messages\": []})"
      ],
      "metadata": {
        "id": "kRSy7I2owylA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_menu() -> str:\n",
        "  \"\"\"Provide the latest up-to-date menu\"\"\"\n",
        "\n",
        "  return \"\"\"\n",
        "  Menu:\n",
        "\n",
        "  Coffee Drinks\n",
        "    Espresso\n",
        "    Americano\n",
        "    Cold Brew\n",
        "    Filter Coffee - South Indian Style\n",
        "    Instant Coffee\n",
        "\n",
        "  Coffee Drinks with Milk\n",
        "    Latte\n",
        "    Cappuccino\n",
        "    Mocha\n",
        "    Flat White\n",
        "    Macchiato\n",
        "    Cortado\n",
        "\n",
        "  Tea Drinks\n",
        "    Masala Chai\n",
        "    Ginger Tea\n",
        "    Cardamom tes\n",
        "    Tulsi Tea\n",
        "    Green Tea\n",
        "    Earl Grey Tea\n",
        "    English Breakfast Tea\n",
        "\n",
        "  Food Items\n",
        "    Sandwiches\n",
        "    Wraps\n",
        "    Salads\n",
        "    Pastries\n",
        "    Cakes\n",
        "    Snacks\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "Wqi3TPepw7f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph==0.2.45 # Install or update langgraph to 0.2.45 or higher\n",
        "# The prebuilt module was added to langgraph version 0.2.45.  Make sure the version is >= 0.2.45."
      ],
      "metadata": {
        "id": "28BRCtIDzPbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph==0.2.45 # Ensure langgraph is installed with the necessary submodule"
      ],
      "metadata": {
        "id": "xFtY9-0hyd4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuit import ToolNode #Import the ToolNode\n",
        "\n",
        "tools = [get_menu]\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def maybe_route_to_tools(state: OrderState) -> literal[\"tools\",\"human\"]:\n",
        "  \"\"\"Route betwee human or tool nodes, depending if a tool call is made\"\"\"\n",
        "  if not (msgs := state.get(\"messages\", [])):\n",
        "    raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "  msg = msgs[-1]\n",
        "\n",
        "  if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "    return \"tools\"\n",
        "  else:\n",
        "    return \"human\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "CwxdNMCexlBX",
        "outputId": "7d2b0360-88dd-4ddf-f6e4-2262670276cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph.prebuit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-d7ca327620fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToolNode\u001b[0m \u001b[0;31m#Import the ToolNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_menu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtool_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.prebuit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
        "  \"\"\"The chat bot with toold. A simple wrapper around model's own chat interface\"\"\"\n",
        "  defaults = {\"order\":{}, \"finished \": False}\n",
        "\n",
        "  if state[\"messages\"]:\n",
        "    new_output = llm_with_tools.invoke([ORDERBOT_SYSINT] + state[\"messages\"])\n",
        "  else:\n",
        "    new_output = AIMessage(content = WELCOME_MSG)\n",
        "\n",
        "  return defautls | state | {\"messages\": [new_output]}\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_with_menu = graph_builder.compile()"
      ],
      "metadata": {
        "id": "dhtS2koBxn_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = graph_with_menu.invoke({\"messages\":[]})"
      ],
      "metadata": {
        "id": "ZKCISu7GxqI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "from random import randint\n",
        "\n",
        "from langgraph.prebuilt import InjectedState\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "\n",
        "@tool\n",
        "def add_to_order(item: str) -> str:\n",
        "  \"\"\"Returns : the user's free-text response\"\"\"\n",
        "\n",
        "@tool\n",
        "def cofirm_order() -> str:\n",
        "  \"\"\"Returns : the user's free-text response\"\"\"\n",
        "\n",
        "@tool\n",
        "def get_order() -> str:\n",
        "  \"\"\"Returns the users orders so far\"\"\"\n",
        "\n",
        "@tool\n",
        "def clear_order():\n",
        "  \"\"\"Removes al items from the user's orders\"\"\"\n",
        "\n",
        "@tool\n",
        "def place_order() -> int:\n",
        "  \"\"\"Returns the estimated number of minutes until the order is ready\"\"\"\n"
      ],
      "metadata": {
        "id": "47W2uNTxxq9h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}